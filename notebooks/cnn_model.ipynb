{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "custom_path = \"E:\\\\Diabetic_Retinopathy_Detection\\\\models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(64 * 56 * 56, 128)  # Adjust the input size based on your image size\n",
    "        self.fc2 = nn.Linear(128, 5)  # Output layer for 5 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 56 * 56)  # Flatten the tensor for the fully connected layer\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/100]: 100%|██████████| 113/113 [03:36<00:00,  1.92s/it, loss=1.16]\n",
      "Epoch [2/100]: 100%|██████████| 113/113 [03:37<00:00,  1.93s/it, loss=1.35] \n",
      "Epoch [3/100]: 100%|██████████| 113/113 [03:37<00:00,  1.93s/it, loss=1.37]\n",
      "Epoch [4/100]: 100%|██████████| 113/113 [03:37<00:00,  1.93s/it, loss=1.3] \n",
      "Epoch [5/100]: 100%|██████████| 113/113 [03:37<00:00,  1.93s/it, loss=1.39]\n",
      "Epoch [6/100]: 100%|██████████| 113/113 [03:38<00:00,  1.93s/it, loss=1.06] \n",
      "Epoch [7/100]: 100%|██████████| 113/113 [03:40<00:00,  1.95s/it, loss=1.13] \n",
      "Epoch [8/100]: 100%|██████████| 113/113 [03:40<00:00,  1.95s/it, loss=1.05] \n",
      "Epoch [9/100]: 100%|██████████| 113/113 [03:39<00:00,  1.95s/it, loss=0.902]\n",
      "Epoch [10/100]: 100%|██████████| 113/113 [03:40<00:00,  1.95s/it, loss=0.943]\n",
      "Epoch [11/100]: 100%|██████████| 113/113 [03:39<00:00,  1.94s/it, loss=0.809]\n",
      "Epoch [12/100]: 100%|██████████| 113/113 [03:39<00:00,  1.94s/it, loss=0.989]\n",
      "Epoch [13/100]: 100%|██████████| 113/113 [03:39<00:00,  1.94s/it, loss=0.825]\n",
      "Epoch [14/100]: 100%|██████████| 113/113 [03:38<00:00,  1.94s/it, loss=0.671]\n",
      "Epoch [15/100]: 100%|██████████| 113/113 [03:39<00:00,  1.94s/it, loss=0.436]\n",
      "Epoch [16/100]: 100%|██████████| 113/113 [03:39<00:00,  1.94s/it, loss=0.438]\n",
      "Epoch [17/100]: 100%|██████████| 113/113 [03:39<00:00,  1.94s/it, loss=0.51] \n",
      "Epoch [18/100]: 100%|██████████| 113/113 [03:39<00:00,  1.94s/it, loss=0.382]\n",
      "Epoch [19/100]: 100%|██████████| 113/113 [03:39<00:00,  1.94s/it, loss=0.278]\n",
      "Epoch [20/100]: 100%|██████████| 113/113 [03:39<00:00,  1.94s/it, loss=0.303]\n",
      "Epoch [21/100]: 100%|██████████| 113/113 [03:39<00:00,  1.94s/it, loss=0.22] \n",
      "Epoch [22/100]: 100%|██████████| 113/113 [03:56<00:00,  2.09s/it, loss=0.2]   \n",
      "Epoch [23/100]: 100%|██████████| 113/113 [03:42<00:00,  1.97s/it, loss=0.191]\n",
      "Epoch [24/100]: 100%|██████████| 113/113 [03:40<00:00,  1.95s/it, loss=0.0971]\n",
      "Epoch [25/100]: 100%|██████████| 113/113 [03:40<00:00,  1.95s/it, loss=0.215] \n",
      "Epoch [26/100]: 100%|██████████| 113/113 [03:48<00:00,  2.02s/it, loss=0.155] \n",
      "Epoch [27/100]: 100%|██████████| 113/113 [03:47<00:00,  2.01s/it, loss=0.0261]\n",
      "Epoch [28/100]: 100%|██████████| 113/113 [03:46<00:00,  2.01s/it, loss=0.0227]\n",
      "Epoch [29/100]: 100%|██████████| 113/113 [03:51<00:00,  2.05s/it, loss=0.14]  \n",
      "Epoch [30/100]: 100%|██████████| 113/113 [03:48<00:00,  2.02s/it, loss=0.0201]\n",
      "Epoch [31/100]: 100%|██████████| 113/113 [03:45<00:00,  1.99s/it, loss=0.233] \n",
      "Epoch [32/100]: 100%|██████████| 113/113 [03:45<00:00,  2.00s/it, loss=0.0471]\n",
      "Epoch [33/100]: 100%|██████████| 113/113 [03:46<00:00,  2.00s/it, loss=0.0443]\n",
      "Epoch [34/100]: 100%|██████████| 113/113 [03:48<00:00,  2.02s/it, loss=0.0222]\n",
      "Epoch [35/100]: 100%|██████████| 113/113 [03:43<00:00,  1.97s/it, loss=0.0464] \n",
      "Epoch [36/100]: 100%|██████████| 113/113 [03:42<00:00,  1.97s/it, loss=0.0133]\n",
      "Epoch [37/100]: 100%|██████████| 113/113 [03:38<00:00,  1.94s/it, loss=0.0122] \n",
      "Epoch [38/100]: 100%|██████████| 113/113 [03:38<00:00,  1.93s/it, loss=0.146]  \n",
      "Epoch [39/100]: 100%|██████████| 113/113 [03:38<00:00,  1.94s/it, loss=0.131]  \n",
      "Epoch [40/100]: 100%|██████████| 113/113 [03:38<00:00,  1.93s/it, loss=0.0137] \n",
      "Epoch [41/100]: 100%|██████████| 113/113 [03:38<00:00,  1.93s/it, loss=0.0194] \n",
      "Epoch [42/100]: 100%|██████████| 113/113 [03:41<00:00,  1.96s/it, loss=0.14]  \n",
      "Epoch [43/100]: 100%|██████████| 113/113 [03:40<00:00,  1.95s/it, loss=0.0243] \n",
      "Epoch [44/100]: 100%|██████████| 113/113 [03:41<00:00,  1.96s/it, loss=0.00383]\n",
      "Epoch [45/100]: 100%|██████████| 113/113 [03:44<00:00,  1.99s/it, loss=0.0884] \n",
      "Epoch [46/100]: 100%|██████████| 113/113 [03:45<00:00,  2.00s/it, loss=0.11]  \n",
      "Epoch [47/100]: 100%|██████████| 113/113 [03:42<00:00,  1.97s/it, loss=0.00377]\n",
      "Epoch [48/100]: 100%|██████████| 113/113 [03:48<00:00,  2.02s/it, loss=0.015]  \n",
      "Epoch [49/100]: 100%|██████████| 113/113 [03:44<00:00,  1.98s/it, loss=0.00659]\n",
      "Epoch [50/100]: 100%|██████████| 113/113 [03:41<00:00,  1.96s/it, loss=0.0876] \n",
      "Epoch [51/100]: 100%|██████████| 113/113 [03:41<00:00,  1.96s/it, loss=0.00723]\n",
      "Epoch [52/100]: 100%|██████████| 113/113 [03:41<00:00,  1.96s/it, loss=0.00166]\n",
      "Epoch [53/100]: 100%|██████████| 113/113 [03:41<00:00,  1.96s/it, loss=0.0373] \n",
      "Epoch [54/100]: 100%|██████████| 113/113 [03:41<00:00,  1.96s/it, loss=0.0396] \n",
      "Epoch [55/100]: 100%|██████████| 113/113 [03:40<00:00,  1.95s/it, loss=0.0348]\n",
      "Epoch [56/100]: 100%|██████████| 113/113 [03:39<00:00,  1.94s/it, loss=0.165] \n",
      "Epoch [57/100]: 100%|██████████| 113/113 [03:38<00:00,  1.93s/it, loss=0.0149] \n",
      "Epoch [58/100]: 100%|██████████| 113/113 [03:38<00:00,  1.93s/it, loss=0.00935]\n",
      "Epoch [59/100]: 100%|██████████| 113/113 [03:38<00:00,  1.93s/it, loss=0.292]  \n",
      "Epoch [60/100]: 100%|██████████| 113/113 [03:38<00:00,  1.93s/it, loss=0.11]   \n",
      "Epoch [61/100]: 100%|██████████| 113/113 [03:38<00:00,  1.94s/it, loss=0.0021] \n",
      "Epoch [62/100]: 100%|██████████| 113/113 [03:39<00:00,  1.94s/it, loss=0.00256]\n",
      "Epoch [63/100]: 100%|██████████| 113/113 [03:38<00:00,  1.94s/it, loss=0.00373]\n",
      "Epoch [64/100]: 100%|██████████| 113/113 [03:38<00:00,  1.94s/it, loss=0.00105]\n",
      "Epoch [65/100]: 100%|██████████| 113/113 [03:38<00:00,  1.94s/it, loss=0.0027] \n",
      "Epoch [66/100]: 100%|██████████| 113/113 [03:44<00:00,  1.98s/it, loss=0.00184]\n",
      "Epoch [67/100]: 100%|██████████| 113/113 [03:47<00:00,  2.01s/it, loss=0.00995]\n",
      "Epoch [68/100]: 100%|██████████| 113/113 [03:46<00:00,  2.00s/it, loss=0.00289]\n",
      "Epoch [69/100]: 100%|██████████| 113/113 [03:41<00:00,  1.96s/it, loss=0.00258]\n",
      "Epoch [70/100]: 100%|██████████| 113/113 [03:40<00:00,  1.95s/it, loss=0.0021] \n",
      "Epoch [71/100]: 100%|██████████| 113/113 [03:40<00:00,  1.95s/it, loss=0.00246]\n",
      "Epoch [72/100]: 100%|██████████| 113/113 [03:40<00:00,  1.95s/it, loss=0.00335]\n",
      "Epoch [73/100]: 100%|██████████| 113/113 [03:40<00:00,  1.95s/it, loss=0.00443]\n",
      "Epoch [74/100]: 100%|██████████| 113/113 [03:40<00:00,  1.95s/it, loss=0.00231]\n",
      "Epoch [75/100]: 100%|██████████| 113/113 [03:40<00:00,  1.96s/it, loss=0.0597] \n",
      "Epoch [76/100]: 100%|██████████| 113/113 [03:40<00:00,  1.95s/it, loss=0.0219]\n",
      "Epoch [77/100]: 100%|██████████| 113/113 [03:40<00:00,  1.95s/it, loss=0.189]  \n",
      "Epoch [78/100]: 100%|██████████| 113/113 [03:40<00:00,  1.95s/it, loss=0.158]  \n",
      "Epoch [79/100]: 100%|██████████| 113/113 [03:43<00:00,  1.98s/it, loss=0.00585]\n",
      "Epoch [80/100]: 100%|██████████| 113/113 [03:45<00:00,  1.99s/it, loss=0.00511]\n",
      "Epoch [81/100]: 100%|██████████| 113/113 [03:41<00:00,  1.96s/it, loss=0.00241]\n",
      "Epoch [82/100]: 100%|██████████| 113/113 [03:43<00:00,  1.98s/it, loss=0.225]  \n",
      "Epoch [83/100]: 100%|██████████| 113/113 [03:45<00:00,  1.99s/it, loss=0.0551] \n",
      "Epoch [84/100]: 100%|██████████| 113/113 [03:42<00:00,  1.97s/it, loss=0.00254]\n",
      "Epoch [85/100]: 100%|██████████| 113/113 [03:42<00:00,  1.97s/it, loss=0.0227] \n",
      "Epoch [86/100]: 100%|██████████| 113/113 [03:42<00:00,  1.97s/it, loss=0.00177] \n",
      "Epoch [87/100]: 100%|██████████| 113/113 [03:54<00:00,  2.07s/it, loss=0.0563] \n",
      "Epoch [88/100]: 100%|██████████| 113/113 [03:59<00:00,  2.12s/it, loss=0.00129]\n",
      "Epoch [89/100]: 100%|██████████| 113/113 [03:57<00:00,  2.10s/it, loss=0.134]  \n",
      "Epoch [90/100]: 100%|██████████| 113/113 [03:46<00:00,  2.00s/it, loss=0.0154] \n",
      "Epoch [91/100]: 100%|██████████| 113/113 [03:43<00:00,  1.98s/it, loss=0.00187]\n",
      "Epoch [92/100]: 100%|██████████| 113/113 [03:43<00:00,  1.98s/it, loss=0.00119] \n",
      "Epoch [93/100]: 100%|██████████| 113/113 [03:42<00:00,  1.97s/it, loss=0.00185] \n",
      "Epoch [94/100]: 100%|██████████| 113/113 [03:44<00:00,  1.99s/it, loss=0.082]   \n",
      "Epoch [95/100]: 100%|██████████| 113/113 [03:44<00:00,  1.98s/it, loss=0.031]  \n",
      "Epoch [96/100]: 100%|██████████| 113/113 [03:43<00:00,  1.98s/it, loss=0.00707]\n",
      "Epoch [97/100]: 100%|██████████| 113/113 [03:47<00:00,  2.01s/it, loss=0.0377] \n",
      "Epoch [98/100]: 100%|██████████| 113/113 [03:50<00:00,  2.04s/it, loss=0.171]  \n",
      "Epoch [99/100]: 100%|██████████| 113/113 [03:48<00:00,  2.02s/it, loss=0.024]   \n",
      "Epoch [100/100]: 100%|██████████| 113/113 [03:49<00:00,  2.03s/it, loss=0.00166]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm  # Import tqdm\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 64\n",
    "learning_rate = 0.0005\n",
    "num_epochs = 100\n",
    "\n",
    "# Dataset loading and preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to 224x224\n",
    "    transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root='e:/Diabetic_Retinopathy_Detection/input/train', transform=transform)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Model, loss function, and optimizer\n",
    "model = CustomCNN()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Wrap train_loader with tqdm for a progress bar\n",
    "    loop = tqdm(train_loader, leave=True)\n",
    "    for images, labels in loop:\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update the progress bar\n",
    "        loop.set_description(f'Epoch [{epoch+1}/{num_epochs}]')\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "    \n",
    "    # Optional: You can add another print statement here if you want more info\n",
    "\n",
    "print(\"Training complete!\")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), os.path.join(custom_path, \"cnn_100.pth\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:51<00:00,  3.06s/it, accuracy=36.44%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test images: 36.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm  # Import tqdm\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 64\n",
    "\n",
    "# Dataset loading and preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to fit the model input\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "test_dataset = datasets.ImageFolder(root='e:/Diabetic_Retinopathy_Detection/input/test', transform=transform)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Load the trained model\n",
    "model = CustomCNN()\n",
    "model.load_state_dict(torch.load('custom_cnn.pth'))\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Evaluate the model\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():  # No need to calculate gradients\n",
    "    # Wrap test_loader with tqdm for a progress bar\n",
    "    loop = tqdm(test_loader, leave=True)\n",
    "    for images, labels in loop:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Optional: Update the progress bar with additional info\n",
    "        loop.set_postfix(accuracy=f'{100 * correct / total:.2f}%')\n",
    "\n",
    "print(f'Accuracy of the model on the test images: {100 * correct / total:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
