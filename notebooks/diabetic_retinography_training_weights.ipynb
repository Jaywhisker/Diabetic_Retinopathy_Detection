{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Creation\n",
    "\n",
    "This is the notebook to train the classification of Diabetic Retinography with CNNs\n",
    "\n",
    "This notebook contains the following\n",
    "1. Dataset Creation and Augmentation\n",
    "2. Train and Eval Functions\n",
    "3. CNN Class Models (InceptionV3, ResNet50, ResNet152, EfficientNet, DenseNet, VGG16, MaxViT)\n",
    "\n",
    "This notebook assumes the following project structure:\n",
    "```bash\n",
    "Root\n",
    "├── notebooks\n",
    "│   └── notebook1.ipynb\n",
    "└── input\n",
    "    └── Data\n",
    "        ├── DDR\n",
    "        │   ├── Train\n",
    "        │   └── Test\n",
    "        ── BEN\n",
    "        │   ├── Train\n",
    "        │   └── Test\n",
    "        ├── CLAHE\n",
    "        │   ├── Train\n",
    "        │   └── Test\n",
    "        ├── UNET_Binary\n",
    "        │   ├── Train\n",
    "        │   └── Test\n",
    "        └── UNET_Multiclass\n",
    "            ├── Train\n",
    "            └── Test\n",
    "```\n",
    "\n",
    "If you do not have the dataset, please download it from our Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Necessary Imports\n",
    "import torch\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.transforms import InterpolationMode\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter required\n",
    "image_size = (299,299)\n",
    "batch_size = 64\n",
    "\n",
    "# Defining Train Transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),  # Flip horizontally with a 50% probability\n",
    "    transforms.RandomVerticalFlip(p=0.5),  # Flip vertically with a 50% probability\n",
    "    transforms.RandomAffine(\n",
    "        degrees=360,  # Rotation\n",
    "        translate=(0.1, 0.1),  # Translation\n",
    "        scale=(0.8, 1.2) #Zooming\n",
    "    ),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "# Defining Evaluation Transforms, no data augmentation\n",
    "eval_transform = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ben Graham dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PyTorch datasets for training and validation\n",
    "ben_train_dataset = datasets.ImageFolder(\n",
    "                    root='../input/grading_images/BEN/train', \n",
    "                    transform=train_transform\n",
    "                    )\n",
    "ben_val_dataset = datasets.ImageFolder(\n",
    "                    root='../input/grading_images/BEN/val', \n",
    "                    transform=eval_transform\n",
    "                    )\n",
    "ben_test_dataset = datasets.ImageFolder(\n",
    "                    root='../input/grading_images/BEN/test', \n",
    "                    transform=eval_transform\n",
    "                    )\n",
    "\n",
    "# Create PyTorch dataloaders for training and validation\n",
    "ben_train_dataloader = torch.utils.data.DataLoader(\n",
    "                    ben_train_dataset,\n",
    "                    batch_size=batch_size, \n",
    "                    shuffle=True\n",
    "                    )\n",
    "ben_val_dataloader = torch.utils.data.DataLoader(\n",
    "                    ben_val_dataset, \n",
    "                    batch_size=batch_size, \n",
    "                    shuffle=True\n",
    "                    )\n",
    "ben_test_dataloader = torch.utils.data.DataLoader(\n",
    "                    ben_test_dataset, \n",
    "                    batch_size=batch_size, \n",
    "                    shuffle=True\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CLAHE dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PyTorch datasets for training and validation\n",
    "clahe_train_dataset = datasets.ImageFolder(\n",
    "                    root='../input/grading_images/CLAHE/train', \n",
    "                    transform=train_transform\n",
    "                    )\n",
    "clahe_val_dataset = datasets.ImageFolder(\n",
    "                    root='../input/grading_images/CLAHE/val', \n",
    "                    transform=eval_transform\n",
    "                    )\n",
    "clahe_test_dataset = datasets.ImageFolder(\n",
    "                    root='../input/grading_images/CLAHE/test', \n",
    "                    transform=eval_transform\n",
    "                    )\n",
    "\n",
    "# Create PyTorch dataloaders for training and validation\n",
    "clahe_train_dataloader = torch.utils.data.DataLoader(\n",
    "                    clahe_train_dataset,\n",
    "                    batch_size=batch_size, \n",
    "                    shuffle=True\n",
    "                    )\n",
    "clahe_val_dataloader = torch.utils.data.DataLoader(\n",
    "                    clahe_val_dataset, \n",
    "                    batch_size=batch_size, \n",
    "                    shuffle=True\n",
    "                    )\n",
    "clahe_test_dataloader = torch.utils.data.DataLoader(\n",
    "                    clahe_test_dataset, \n",
    "                    batch_size=batch_size, \n",
    "                    shuffle=True\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UNET_Binary Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PyTorch datasets for training and validation\n",
    "unetb_train_dataset = datasets.ImageFolder(\n",
    "                    root='../input/grading_images/UNET_Binary/train', \n",
    "                    transform=train_transform\n",
    "                    )\n",
    "unetb_val_dataset = datasets.ImageFolder(\n",
    "                    root='../input/grading_images/UNET_Binary/val', \n",
    "                    transform=eval_transform\n",
    "                    )\n",
    "unetb_test_dataset = datasets.ImageFolder(\n",
    "                    root='../input/grading_images/UNET_Binary/test', \n",
    "                    transform=eval_transform\n",
    "                    )\n",
    "\n",
    "# Create PyTorch dataloaders for training and validation\n",
    "unetb_train_dataloader = torch.utils.data.DataLoader(\n",
    "                    unetb_train_dataset,\n",
    "                    batch_size=batch_size, \n",
    "                    shuffle=True\n",
    "                    )\n",
    "unetb_val_dataloader = torch.utils.data.DataLoader(\n",
    "                    unetb_val_dataset, \n",
    "                    batch_size=batch_size, \n",
    "                    shuffle=True\n",
    "                    )\n",
    "unetb_test_dataloader = torch.utils.data.DataLoader(\n",
    "                    unetb_test_dataset, \n",
    "                    batch_size=batch_size, \n",
    "                    shuffle=True\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UNET_Multiclass Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PyTorch datasets for training and validation\n",
    "unetm_train_dataset = datasets.ImageFolder(\n",
    "                    root='../input/grading_images/UNET_Multiclass/train', \n",
    "                    transform=train_transform\n",
    "                    )\n",
    "unetm_val_dataset = datasets.ImageFolder(\n",
    "                    root='../input/grading_images/UNET_Multiclass/val', \n",
    "                    transform=eval_transform\n",
    "                    )\n",
    "unetm_test_dataset = datasets.ImageFolder(\n",
    "                    root='../input/grading_images/UNET_Multiclass/test', \n",
    "                    transform=eval_transform\n",
    "                    )\n",
    "\n",
    "# Create PyTorch dataloaders for training and validation\n",
    "unetm_train_dataloader = torch.utils.data.DataLoader(\n",
    "                    unetm_train_dataset,\n",
    "                    batch_size=batch_size, \n",
    "                    shuffle=True\n",
    "                    )\n",
    "unetm_val_dataloader = torch.utils.data.DataLoader(\n",
    "                    unetm_val_dataset, \n",
    "                    batch_size=batch_size, \n",
    "                    shuffle=True\n",
    "                    )\n",
    "unetm_test_dataloader = torch.utils.data.DataLoader(\n",
    "                    unetm_test_dataset, \n",
    "                    batch_size=batch_size, \n",
    "                    shuffle=True\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise_img(dataloader, class_list: list):\n",
    "    \"\"\"\n",
    "    Function to visualize the first 9 images of the dataset.\n",
    "\n",
    "    Args:\n",
    "        dataloader (DataLoader): PyTorch DataLoader object containing the dataset to visualize.\n",
    "        class_list (list): List of class labels.\n",
    "    \"\"\"\n",
    "    #Get the first batch of images and labels\n",
    "    train_images, train_labels = next(iter(dataloader))\n",
    "    batch_size = train_images.size(0)  # Get the batch size\n",
    "\n",
    "    #Print the shape of the batch\n",
    "    print(f\"Images batch shape: {train_images.size()}\")\n",
    "    print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "\n",
    "    #Create a 3x3 grid for visualization\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(9, 9))\n",
    "\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            #Get the index of the image in the batch\n",
    "            index = i * 3 + j\n",
    "\n",
    "            if index < batch_size:\n",
    "                #Prepare image to print\n",
    "                img = train_images[index].squeeze().numpy().transpose((1, 2, 0))\n",
    "                label = train_labels[index].item()\n",
    "\n",
    "                #Plot the image\n",
    "                axes[i, j].imshow(img)\n",
    "                axes[i, j].axis('off')\n",
    "                axes[i, j].set_title(f'Label: {label}, {class_list[label]}', loc='left')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise_img(ben_train_dataloader, ben_train_dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise_img(clahe_train_dataloader, clahe_train_dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise_img(unetb_train_dataloader, unetb_train_dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise_img(unetm_train_dataloader, unetm_train_dataset.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Eval Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def eval(model, \n",
    "         criterion, \n",
    "         img_size:tuple,\n",
    "         val_dataloader, \n",
    "         device='cuda'):\n",
    "    \"\"\"\n",
    "    Evaluation function for finetuning CNN models with a model object,\n",
    "    incorporating average sensitivity for a multiclass problem.\n",
    "\n",
    "    Sensitivity function: True Positives / (True Positives + False Negatives)\n",
    "\n",
    "    Args:\n",
    "        model: model to be trained\n",
    "        criterion: loss function\n",
    "        img_size (tuple): image size of dataset for model. All inputs will be resized to image size\n",
    "        val_dataloader: val / test dataloader\n",
    "        device (str, optional): 'cpu' or 'cuda', defaults to cuda.\n",
    "\n",
    "    Returns:\n",
    "        val_loss: float of the average val loss.\n",
    "        val_accuracy: float of the accuracy.\n",
    "        val_sensitivity: float of the average sensitivity across all classes.\n",
    "    \"\"\"\n",
    "\n",
    "    model = model.to(device)\n",
    "    \n",
    "    #set model to eval mode\n",
    "    model.eval()\n",
    "\n",
    "    #variables \n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    n_classes = 5\n",
    "    true_positives = [0] * n_classes #stores num of true positives per class\n",
    "    actual_positives = [0] * n_classes #stores total number of positives per class\n",
    "    total_sensitivity = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for image, label in val_dataloader:\n",
    "            batch_sensitivity = 0\n",
    "\n",
    "            #resize image with bilinear, same as torchvision.transforms.Resize()\n",
    "            image = torch.nn.functional.interpolate(image, size=img_size, mode='bilinear') \n",
    "            image, label = image.to(device), label.to(device)\n",
    "\n",
    "            outputs = model(image)  #predict label\n",
    "            loss = criterion(outputs, label)  #calculate loss\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1) #get prediction\n",
    "            total += label.size(0)\n",
    "            correct += (predicted == label).sum().item()\n",
    "\n",
    "            for i in range(n_classes):\n",
    "                true_positives[i] += ((predicted == i) & (label == i)).sum().item() #true positives\n",
    "                actual_positives[i] += (label == i).sum().item() #true positives + false negatives\n",
    "            \n",
    "                if (label == i).sum().item() > 0:\n",
    "                    batch_sensitivity += true_positives[i] / actual_positives[i]\n",
    "\n",
    "                else:\n",
    "                    pass\n",
    "            \n",
    "            total_sensitivity += batch_sensitivity/n_classes #average sensitivity for batch\n",
    "\n",
    "    # Calculate accuracy, avg loss, and avg sensitivity\n",
    "    accuracy = (correct / total) * 100\n",
    "    avg_val_loss = val_loss / len(val_dataloader)\n",
    "    avg_sensitivity = total_sensitivity/len(val_dataloader)\n",
    "    \n",
    "    return avg_val_loss, accuracy, avg_sensitivity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, \n",
    "          criterion, \n",
    "          optimiser, \n",
    "          img_size:tuple,\n",
    "          train_dataloader, \n",
    "          val_dataloader=None, \n",
    "          saving_metric:str='sensitivity',\n",
    "          num_epochs:int=25, \n",
    "          device:str='cuda', \n",
    "          model_name:str=None):\n",
    "    \"\"\"\n",
    "    Training Function to train model\n",
    "    Runs validation for each epoch to calculate: Validation Loss, Validation Accuracy, Validation Sensitivity\n",
    "    Best and last model will be saved to ../models/cnn under {model_name}_best.pt and {model_name}_last.pt\n",
    "    \n",
    "    Args:\n",
    "        model: model to be trained\n",
    "        criterion: loss function\n",
    "        optimiser: optimiser chosen\n",
    "        img_size (tuple): image size of dataset for model. All inputs will be resized to image size\n",
    "        train_dataloader: train dataloader\n",
    "        val_dataloader (optional): val dataloader, if None no validation will be calculated. Defaults to None.\n",
    "        saving_metric (str, optional): saving metrics for best model, either \"loss\", \"accuracy\", or \"sensitivity\". Defaults to 'sensitivity'.\n",
    "        num_epochs (int, optional): number of training epochs. Defaults to 25.\n",
    "        device (str, optional): cuda or cpu. Defaults to 'cuda'.\n",
    "        model_name (str, optional): model name to be saved, if None no model will be saved. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        results_dataframe: dataframe of [model, train_loss, val_loss, val_accuracy, val_sensitivity] where each row is each epoch\n",
    "    \"\"\"\n",
    "\n",
    "    if saving_metric not in [\"loss\", \"accuracy\", \"sensitivity\"]:\n",
    "        raise Exception(\"Invalid saving metrics found, please only use loss, accuracy or sensitivity\")\n",
    "\n",
    "    #initialising results container\n",
    "    results = pd.DataFrame(columns=[\"Model\", \"train loss\", \"val loss\", \"val accuracy\", \"val sensitivity\"])\n",
    "    \n",
    "    #placeholders\n",
    "    val_loss = ''\n",
    "    val_accuracy = ''\n",
    "    val_sensitivity = ''\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        #initialising training\n",
    "        model.train()\n",
    "        training_loss = 0.0\n",
    "\n",
    "        for image, label in tqdm(train_dataloader):\n",
    "            \n",
    "            #resize image with bilinear, same as torchvision.transforms.Resize()\n",
    "            image = torch.nn.functional.interpolate(image, size=img_size, mode='bilinear') \n",
    "            image, label = image.to(device), label.to(device)\n",
    "\n",
    "            optimiser.zero_grad()\n",
    "            outputs = model(image)\n",
    "            #calculate loss and train model\n",
    "            loss = criterion(outputs, label)\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "            training_loss += loss.item() #update the training loss\n",
    "\n",
    "        epoch_loss = training_loss / len(train_dataloader) #calculate training loss in epoch\n",
    "        print(f\"Epoch {epoch+1} completed, training loss: {epoch_loss}\")\n",
    "\n",
    "        #validation\n",
    "        if val_dataloader is not None:\n",
    "            model.eval()  #set model to evaluate mode\n",
    "            val_loss, val_accuracy,  val_sensitivity = eval(model=model, \n",
    "                                                               criterion=criterion,\n",
    "                                                                val_dataloader=val_dataloader, \n",
    "                                                                img_size = img_size,\n",
    "                                                                device=device) \n",
    "            \n",
    "            print(f\"Validation loss: {val_loss}, Validation Accuracy: {val_accuracy:.2f}, Validation Sensitivty: {val_sensitivity:2f}\")\n",
    "            \n",
    "\n",
    "            if saving_metric == 'loss' and len(results) > 0 and val_loss < min(results['val loss'].to_list()):\n",
    "                torch.save(model, f'../models/cnn/{model_name}_best.pt')\n",
    "                print(\"Best model saved\")\n",
    "\n",
    "            elif saving_metric == 'accuracy' and len(results) > 0 and val_accuracy > max(results['val accuracy'].to_list()):\n",
    "                torch.save(model, f'../models/cnn/{model_name}_best.pt')\n",
    "                print(\"Best model saved\")\n",
    "\n",
    "            elif saving_metric == 'sensitivity' and len(results) > 0 and val_sensitivity > max(results['val sensitivity'].to_list()):\n",
    "                torch.save(model, f'../models/cnn/{model_name}_best.pt')\n",
    "                print(\"Best model saved\")\n",
    "            \n",
    "        #updating results\n",
    "        results.loc[len(results)] = [model_name, epoch_loss, val_loss, val_accuracy, val_sensitivity]\n",
    "\n",
    "\n",
    "    #save the last model\n",
    "    if model_name is not None:\n",
    "        torch.save(model, f'../models/cnn/{model_name}_last.pt')\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreTrainedCNNModels(torch.nn.Module):\n",
    "    def __init__(self, model_type:str, num_unfreeze:int, num_class:int):\n",
    "        super(PreTrainedCNNModels, self).__init__()\n",
    "        \"\"\"\n",
    "        Class that contains InceptionV3, Resnet50, Resnet152, EfficientNet, DenseNet, VGG16, MaxVit fine tuned models\n",
    "\n",
    "        Args:\n",
    "            model_type (str): Determines which pre-trained models to use\n",
    "                              Must be: InceptionV3, Resnet50, Resnet152, EfficientNet, DenseNet, VGG16, MaxVit\n",
    "            num_unfreeze (int): Number of layers to unfreeze and finetune\n",
    "            num_class (int): Number of output classes for the classification\n",
    "        \"\"\"\n",
    "        #selecting model type\n",
    "        if model_type == 'InceptionV3':\n",
    "            self.model = models.inception_v3(weights=models.Inception_V3_Weights.DEFAULT)\n",
    "            self.model.aux_logits = False\n",
    "\n",
    "        elif model_type == 'Resnet50':\n",
    "            self.model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "\n",
    "        elif model_type == 'Resnet152':\n",
    "            self.model = models.resnet152(weights=models.ResNet152_Weights.DEFAULT)\n",
    "\n",
    "        elif model_type == 'EfficientNet':\n",
    "            self.model = models.efficientnet_v2_s(weights=models.EfficientNet_V2_S_Weights.DEFAULT)\n",
    "\n",
    "        elif model_type == 'DenseNet':\n",
    "            self.model = models.densenet121(weights=models.DenseNet121_Weights.DEFAULT)\n",
    "        \n",
    "        elif model_type == 'VGG16':\n",
    "            self.model = models.vgg16_bn(weights=models.VGG16_BN_Weights.DEFAULT)\n",
    "\n",
    "        elif model_type == 'MaxVit':\n",
    "            self.model = models.maxvit_t(weights=models.MaxVit_T_Weights.DEFAULT)\n",
    "        \n",
    "        else:\n",
    "            raise Exception(\"Invalid model type chosen. Please select one of the following\\n[InceptionV3, Resnet50, Resnet152, EfficientNet, DenseNet, VGG16, MaxVit]\")\n",
    "\n",
    "        \n",
    "        #modifying final layer\n",
    "        if model_type in ['InceptionV3', 'Resnet50', 'Resnet152']:\n",
    "            self.model.fc = torch.nn.Linear(self.model.fc.in_features, num_class)\n",
    "\n",
    "        elif model_type == 'DenseNet':\n",
    "            self.model.classifier = torch.nn.Linear(self.model.classifier.in_features, num_class)\n",
    "\n",
    "        else:\n",
    "            self.model.classifier[-1] = torch.nn.Linear(self.model.classifier[-1].in_features, num_class)\n",
    "\n",
    "\n",
    "        model_paramteres = list(self.model.parameters())\n",
    "        #unfreeze last num_unfreeze layers\n",
    "        for param in model_paramteres[-num_unfreeze:]:\n",
    "            param.requires_grad = True\n",
    "\n",
    "        #freeze rest of the layers\n",
    "        for param in model_paramteres[:-num_unfreeze]:\n",
    "            param.requires_grad = False\n",
    "\n",
    "\n",
    "    def forward(self, images):\n",
    "        return self.model(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training all model with weighted(formula) class\n",
    "\n",
    "Training all model with Cross Entropy Loss with any class weights on Ben Graham dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_class_weights(image_folder_dataloader):\n",
    "    # Counting the number of samples in each class\n",
    "    class_counts = np.bincount(image_folder_dataloader.dataset.targets)\n",
    "    total_samples = sum(class_counts)\n",
    "    num_classes = len(class_counts)\n",
    "    \n",
    "    # Calculating class weights inversely proportional to the number of samples in each class\n",
    "    weights = total_samples / (num_classes * class_counts)\n",
    "    \n",
    "    # Normalizing the weights so that the weight for class 0 is 1\n",
    "    normalized_weights = weights / weights[0]\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = calculate_class_weights(ben_train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list = [['InceptionV3', (299,299)],\n",
    "               ['Resnet50', (224,224)],\n",
    "               ['Resnet152',(224,224)],\n",
    "               ['EfficientNet',(224,224)],\n",
    "               ['DenseNet',(224,224)],\n",
    "               ['VGG16',(224,224)],\n",
    "               ['MaxVit', (224,224)]]\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "num_epochs = 50\n",
    "\n",
    "all_results = pd.DataFrame(columns=[\"Model\", \"train loss\", \"val loss\", \"val accuracy\", \"val sensitivity\"])\n",
    "\n",
    "for model_name, img_size in models_list:\n",
    "\n",
    "    #clear cuda memory\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    model = PreTrainedCNNModels(model_name, 2, len(ben_train_dataset.classes)).to(device)\n",
    "    criterion=torch.nn.CrossEntropyLoss(weight=torch.tensor(class_weights, dtype=torch.float32).to(device))\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "\n",
    "    print(f\"-------------Training {model_name}------------\")\n",
    "    model_result = train(model,\n",
    "                         criterion,\n",
    "                         optimizer,\n",
    "                         img_size,\n",
    "                         ben_train_dataloader,\n",
    "                         ben_val_dataloader,\n",
    "                         'sensitivity',\n",
    "                         num_epochs,\n",
    "                         device,\n",
    "                         f\"{model_name}_weighted\")\n",
    "    \n",
    "    all_results =  pd.concat([all_results, model_result])\n",
    "\n",
    "all_results.to_csv(\"results/cnn_weighted.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list = [['InceptionV3', (299,299)],\n",
    "               ['Resnet50', (224,224)],\n",
    "               ['Resnet152',(224,224)],\n",
    "               ['EfficientNet',(224,224)],\n",
    "               ['DenseNet',(224,224)],\n",
    "               ['VGG16',(224,224)],\n",
    "               ['MaxVit', (224,224)]]\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "for model_name, img_size in models_list:\n",
    "\n",
    "    #clear cuda memory\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    best_model = torch.load(f'../models/cnn/{model_name}_weighted_best.pt')\n",
    "    last_model = torch.load(f'../models/cnn/{model_name}_weighted_last.pt')\n",
    "    criterion=torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    print(f\"-------------Evluating {model_name}------------\")\n",
    "    loss, accuracy, sensitivity = eval(best_model,\n",
    "                                        criterion,\n",
    "                                        img_size,\n",
    "                                        ben_test_dataloader,\n",
    "                                        device)\n",
    "    print(f\"Best Model - Test Loss: {loss}, Test Accuracy: {accuracy}, Test Sensitivity: {sensitivity}\")\n",
    "    loss, accuracy, sensitivity = eval(last_model,\n",
    "                                        criterion,\n",
    "                                        img_size,\n",
    "                                        ben_test_dataloader,\n",
    "                                        device)\n",
    "    print(f\"Last Model - Test Loss: {loss}, Test Accuracy: {accuracy}, Test Sensitivity: {sensitivity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv(\"results/cnn_weighted.csv\")\n",
    "grouped_data = data.groupby('Model')\n",
    "\n",
    "for model, model_data in grouped_data:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(model_data.index, model_data['train loss'], label='Train Loss')\n",
    "    plt.plot(model_data.index, model_data['val loss'], label='Validation Loss')\n",
    "    plt.plot(model_data.index, model_data['val sensitivity'], label='Validation Sensitivity')\n",
    "    \n",
    "    plt.title(f'{model} Metrics')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
